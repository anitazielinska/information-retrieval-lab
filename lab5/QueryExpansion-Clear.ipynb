{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Expansion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0) Just some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import common as cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Simple search engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1) Get acquainted with the below class. There are several TODOs. However, DO NOT complete them now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aaai', 'about', 'academic', 'access', 'acquired', 'acquisition', 'action', 'activity', 'actual', 'adaptive', 'add', 'advance', 'agricultural', 'aha', 'aim', 'alert', 'algorithm', 'all', 'analysis', 'and', 'announcement', 'answer', 'anyone', 'application', 'applied', 'apply', 'applying', 'approach', 'approache', 'april', 'archive', 'are', 'area', 'areas', 'article', 'artificial', 'asked', 'august', 'author', 'automated', 'automatically', 'autonomous', 'available', 'awards', 'backend', 'backgammon', 'baldi', 'based', 'basic', 'bayesian']\n"
     ]
    }
   ],
   "source": [
    "class Dictionary:\n",
    "    def __init__(self):\n",
    "        ### keeps unique terms (SORTED!)\n",
    "        self.terms = self.loadTerms(\"terms.txt\")\n",
    "        self.idfs = [] ### IDF coefficients\n",
    "        self.corM = [] ### a correlation matrix\n",
    "\n",
    "    ### load terms\n",
    "    def loadTerms(self, fileName):\n",
    "        file = open(fileName,'r', encoding='utf-8-sig')\n",
    "        k = [self.proc(s) for s in file.readlines()]\n",
    "        k.sort()\n",
    "        return k\n",
    "\n",
    "    ### ignore it\n",
    "    def proc(self, s):\n",
    "        if s[-1] == '\\n': return s[:-1]\n",
    "        else: return s\n",
    "    \n",
    "    ### DONE\n",
    "    def computeIDFs(self, documents):\n",
    "        docs_total = len(documents)\n",
    "        docs_occur = 0\n",
    "        self.idfs = []\n",
    "        for term in self.terms:\n",
    "            for doc in documents:\n",
    "                if term in doc.tokens:\n",
    "                    docs_occur += 1\n",
    "            self.idfs.append(math.log(docs_total/docs_occur, 2))\n",
    "    \n",
    "    ### DONE\n",
    "    def computeCorM(self, documents):\n",
    "        #create and initalize matrixA\n",
    "        matrixA = np.zeros((len(self.terms), len(documents)))\n",
    "        for rid,term in enumerate(self.terms):\n",
    "            for cid, doc in enumerate(documents):\n",
    "                for token in doc.tokens:\n",
    "                    if token == term:\n",
    "                        matrixA[rid][cid] += 1\n",
    "        \n",
    "        #calculate vector length\n",
    "        tVec = []\n",
    "        for row in matrixA:\n",
    "            tVec.append(np.linalg.norm(row))\n",
    "        \n",
    "        #normalize\n",
    "        for row in range(len(matrixA)):\n",
    "            for col in range(len(matrixA[0])):\n",
    "                matrixA[row][col] = matrixA[row][col]/tVec[row]\n",
    "        \n",
    "        #transpose matrixA\n",
    "        matrixAT = np.transpose(matrixA)\n",
    "        \n",
    "        self.corM = np.matmul(matrixA, matrixAT)\n",
    "        for i in range(len(self.corM)):\n",
    "            self.corM[i][i] = -1\n",
    "        \n",
    "        \n",
    "\n",
    "### SOME DEBUG\n",
    "dictionary = Dictionary()\n",
    "print(dictionary.terms[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2) Load files: here we load some example collection of documents. RAW_DOCUMENTS = just strings. Check if the documents are loaded correctly (e.g., print RAW_DOCUMENTS[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "David W. Aha:  Machine Learning Page\n",
      " Machine Learning Resources. Suggestions welcome. ... (WizRule); ZDM Scientific\n",
      " Ltd. Conference Announcements. Courses on Machine Learning. Data Repositories. ... \n",
      " Description: Comprehensive machine learning resources from Applications to Tutorials.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RAW_DOCUMENTS = cm.loadDocuments(\"documents.txt\")\n",
    "### SOME DEBUG\n",
    "print(RAW_DOCUMENTS[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['david', 'aha', 'machine', 'learning', 'page', 'machine', 'learning', 'resource', 'suggestion', 'welcome', 'wizrule', 'zdm', 'scientific', 'ltd', 'conference', 'announcement', 'course', 'machine', 'learning', 'data', 'repository', 'description', 'comprehensive', 'machine', 'learning', 'resource', 'from', 'application', 'tutorials']\n"
     ]
    }
   ],
   "source": [
    "### SOME DEBUG, JUST RUN; check if (a) common.py is imported correctly and (b) \n",
    "### tokens are correctly derived from some document (e.g., RAW_DOCUMENTS[0])\n",
    "print(cm.simpleTextProcessing(RAW_DOCUMENTS[0], re))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3) Get acquainted with the below class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Document:\n",
    "    def __init__(self, doc_id, raw_document, dictionary):\n",
    "        self.doc_id = doc_id ### DOC ID, simply 0,1,2,3....\n",
    "        self.raw_document = raw_document ### raw data, i.e., string data\n",
    "        self.dictionary = dictionary # reference to the dictionary\n",
    "        \n",
    "        ### DOCUMENT REPRESENTATIONS\n",
    "        self.tokens = cm.simpleTextProcessing(raw_document, re) ### get terms\n",
    "        self.bow = {} # Bag Of Words (BOW - number of term occurences)\n",
    "        self.tf = {} # TF representation\n",
    "        self.tf_idf = {} # TF-IDF representation\n",
    "\n",
    "    ### DONE\n",
    "    def computeBOW_Representation(self):\n",
    "        self.bow = {}\n",
    "        for term in self.tokens:\n",
    "            if term in self.bow.keys():\n",
    "                self.bow[term] += 1\n",
    "            else:\n",
    "                self.bow[term] = 1\n",
    "    \n",
    "    ### DONE\n",
    "    def computeTF_Representation(self):\n",
    "        self.tf = {}\n",
    "        max_occur = 1\n",
    "        for term in self.tokens:\n",
    "            if term in self.tf.keys():\n",
    "                self.tf[term] += 1\n",
    "                max_occur = max(max_occur, self.tf[term])\n",
    "            else:\n",
    "                self.tf[term] = 1\n",
    "        for key, value in self.tf.items():\n",
    "            self.tf[key] = value/max_occur\n",
    "    \n",
    "    ### DONE\n",
    "    def computeTF_IDF_Representation(self):\n",
    "        self.tf_idf = {}\n",
    "        for term, tfi in self.tf.items():\n",
    "            try:\n",
    "                idfi = self.dictionary.idfs[self.dictionary.terms.index(term)]\n",
    "            except:\n",
    "                idfi = 0\n",
    "            self.tf_idf[term] = tfi*idfi\n",
    "        \n",
    "    \n",
    "    def computeRepresentations(self):\n",
    "        self.computeBOW_Representation()\n",
    "        self.computeTF_Representation()\n",
    "        self.computeTF_IDF_Representation()\n",
    "    \n",
    "documents = [Document(i, RAW_DOCUMENTS[i], dictionary) for i in range(len(RAW_DOCUMENTS))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4) Compute IDFs here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['acquired', 3.137503523749935], ['access', 3.289506617194985], ['academic', 3.652076696579693], ['about', 3.8744691179161412], ['aaai', 5.459431618637297]]\n",
      "[['zdm', -4.083600201617941], ['young', -4.082632923646146], ['you', -4.0816649967122265], ['york', -4.077786781901299], ['yahoo', -4.076815597050831]]\n"
     ]
    }
   ],
   "source": [
    "### DONE\n",
    "dictionary.computeIDFs(documents)\n",
    "\n",
    "### SOME DEBUG\n",
    "res = [[dictionary.terms[i], dictionary.idfs[i]] for i in range(len(dictionary.terms))]\n",
    "res.sort(key = lambda x: x[1])\n",
    "# LEAST COMMON WORDS - HIGH IDF\n",
    "print(res[-5:])\n",
    "# MOST COMMON WORDS - LOW IDF\n",
    "print(res[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5) Compute the document representations (for each document run computeRepresentations())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'david': 1, 'aha': 1, 'machine': 4, 'learning': 4, 'page': 1, 'resource': 2, 'suggestion': 1, 'welcome': 1, 'wizrule': 1, 'zdm': 1, 'scientific': 1, 'ltd': 1, 'conference': 1, 'announcement': 1, 'course': 1, 'data': 1, 'repository': 1, 'description': 1, 'comprehensive': 1, 'from': 1, 'application': 1, 'tutorials': 1}\n",
      "{'dataset': 0.6666666666666666, 'for': 0.3333333333333333, 'machine': 0.6666666666666666, 'learning': 0.6666666666666666, 'knowledge': 1.0, 'discovery': 0.6666666666666666, 'data': 0.6666666666666666, 'mining': 0.6666666666666666, 'add': 0.3333333333333333, 'update': 0.3333333333333333, 'the': 0.3333333333333333, 'mlnetois': 0.3333333333333333, 'event': 0.3333333333333333, 'related': 0.3333333333333333, 'acquisition': 0.3333333333333333, 'etc': 0.3333333333333333}\n",
      "{'and': 0.19264507794239583, 'machine': -3.2870827025011664, 'learning': -3.0893902898214542, 'fall': -0.7317348032968899, 'this': -1.3215782233936009, 'course': -0.5172652122619856, 'cover': -0.524663794300051, 'the': -1.3148818392013122, 'theory': -1.3173597897915912, 'practice': -1.1981647542979357, 'from': -0.7963971072640136, 'variety': -1.3404528608195065, 'perspective': -1.1913304609667177}\n"
     ]
    }
   ],
   "source": [
    "for d in documents: d.computeRepresentations()\n",
    "### SOME DEBUG (you should see some 4s - which terms are these?)\n",
    "print(documents[0].bow)\n",
    "print(documents[5].tf)\n",
    "print(documents[7].tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.6) Finish the below method. It should compute and return a cosine similarity (v1 and v2 are two vectors - tf-idf representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DONE\n",
    "def getSimilarity(v1i, v2i):\n",
    "    v1 = list(v1i.values())\n",
    "    v2 = list(v2i.values())\n",
    "    \n",
    "    # make the same length\n",
    "    while len(v1) < len(v2):\n",
    "        v1.append(0)\n",
    "    while len(v2) < len(v1):\n",
    "        v2.append(0)\n",
    "    dot = np.dot(v1, v2)\n",
    "    normv1 = np.linalg.norm(v1)\n",
    "    normv2 = np.linalg.norm(v2)\n",
    "    cos = dot / (normv1*normv2)\n",
    "    return cos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.7) Run the below script for different queries. getTopResults seeks for documents being the most similar/relevant to the query. Do you find the results satisfactory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"machine learning\"\n",
    "#query = \"academic research\"\n",
    "#query = \"international conference\"\n",
    "#query = \"international conference washington\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK = 1 WITH SIMILARITY = 0.8795110578261387 | DOC ID = 63\n",
      "AI / Machine Learning Resources\n",
      " AI / Machine Learning Resources. General Machine Learning. The Journal\n",
      " of Machine Learning. MLnet Machine Learning Archive at GMD. The ... \n",
      "\n",
      "\n",
      "RANK = 2 WITH SIMILARITY = 0.8740788455239175 | DOC ID = 34\n",
      "Machine Learning\n",
      " Machine Learning. Related Sites. Machine Learning Resources courtesy\n",
      " of David Aha A Machine Learning Tutorial a good overview of the ... \n",
      "\n",
      "\n",
      "RANK = 3 WITH SIMILARITY = 0.8666466425586407 | DOC ID = 77\n",
      "Machine Learning\n",
      " Machine Learning. Machine Learning Home Page (Editor) Machine Learning Home\n",
      " Page (Publisher) Machine Learning Online by Kluwer Academic Publishers: ... \n",
      "\n",
      "\n",
      "RANK = 4 WITH SIMILARITY = 0.8587418957884306 | DOC ID = 28\n",
      "Machine Learning\n",
      " 6.858/18.428: Machine Learning. Available Lecture Notes. ... Defining models for\n",
      " machine learning. Learning conjunctions in the mistake-bounded model. ... \n",
      "\n",
      "\n",
      "RANK = 5 WITH SIMILARITY = 0.8328803549278195 | DOC ID = 29\n",
      "Machine Learning\n",
      " 6.858/18.428: Machine Learning. ... This course deals with the following topics:\n",
      " Formal models of machine learning; Learning concepts from examples; ... \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def getTopResults(query, documents, dictionary, similarity, top = 5):\n",
    "    qd = Document(-1, query, dictionary)\n",
    "    qd.computeRepresentations()\n",
    "    ranks = [[d, getSimilarity(d.tf_idf, qd.tf_idf)] for d in documents]\n",
    "    ranks.sort(key=lambda x: -x[1])\n",
    "    for i in range(top):\n",
    "        print(\"RANK = \" + str(i+1) + \" WITH SIMILARITY = \" + str(ranks[i][1]) + \" | DOC ID = \" + str(ranks[i][0].doc_id))\n",
    "        print(ranks[i][0].raw_document)\n",
    "        print(\"\")\n",
    "\n",
    "getTopResults(query, documents, dictionary, getSimilarity, top = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Query expansion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1) Correlation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.1) Finish dictionary.computeCorM method (see class Dictionary). It should generate a correlation matrix (correlation between terms).\n",
    "\n",
    "IMPORTANT: although corM[ i ][ i ] (for each i) should be 1.0, set it to -1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.         -1.          0.         ...  0.18898224  0.\n",
      "   0.        ]\n",
      " [ 0.          0.         -1.         ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.          0.18898224  0.         ... -1.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.         -1.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "  -1.        ]]\n"
     ]
    }
   ],
   "source": [
    "### DONE\n",
    "dictionary.computeCorM(documents)\n",
    "print(dictionary.corM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.2) Finish the below method. For each term in the query (you must parse the query, see getTopResults() method), find another term which is the most correlated with the input term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions\n",
      "learning 0.9700552531915929\n",
      "the 0.6711549305747254\n",
      "description 0.5852726298569305\n",
      "and 0.5653332650783621\n",
      "for 0.44240101088746486\n",
      "page 0.4135841780912734\n",
      "resource 0.4085035786329266\n",
      "research 0.3812617661967056\n",
      "group 0.3793557371640793\n",
      "home 0.3516916400856809\n"
     ]
    }
   ],
   "source": [
    "query = \"machine\"\n",
    "#query = \"algorithm\"\n",
    "# query = \"learning\"\n",
    "# query = \"conference\"\n",
    "# query = \"research\"\n",
    "# query = \"concept\"\n",
    "\n",
    "def suggestKeywords(query, dictionary):\n",
    "    qd = Document(-1, query, dictionary)\n",
    "    qd.computeRepresentations()\n",
    "    queri = dictionary.terms.index(query)\n",
    "    ### DONE\n",
    "    ranking = []\n",
    "    print(\"Suggestions\")\n",
    "    for i, corr in enumerate(dictionary.corM[queri]):\n",
    "        ranking.append([dictionary.terms[i], corr])\n",
    "    ranking.sort(key=lambda x: -x[1])\n",
    "    for i in ranking[:10]:\n",
    "        print(i[0], i[1])\n",
    "    pass\n",
    "        \n",
    "suggestKeywords(query, dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2) Rocchio algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\overrightarrow{q_{m}} = \\alpha \\overrightarrow{q} + \\left(\\beta \\cdot \\dfrac{1}{|D_{r}|} \\sum_{\\overrightarrow{D_j} \\in D_{r}} \\overrightarrow{D_j} \\right) - \\left(\\gamma \\cdot \\dfrac{1}{|D_{nr}|} \\sum_{\\overrightarrow{D_j} \\in D_{nr}} \\overrightarrow{D_j} \\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.1) Firstly, run the below code. Observe the results. Assume that we do not like the first and the second result (Docs 63 and 77). However, assume that docs 29 and 36 are satisfactory. Now, modfify the method. It should alter the query vector, according to Rocchio algorithm. Check the result for the above considered scenario (relevant docs = 29 and 36; not relevant = 63 and 77). Check the results for different values of alpha, beta, and gamma coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK = 1 WITH SIMILARITY = 0.8760674903105631 | DOC ID = 63\n",
      "AI / Machine Learning Resources\n",
      " AI / Machine Learning Resources. General Machine Learning. The Journal\n",
      " of Machine Learning. MLnet Machine Learning Archive at GMD. The ... \n",
      "\n",
      "\n",
      "RANK = 2 WITH SIMILARITY = 0.8706565468595463 | DOC ID = 34\n",
      "Machine Learning\n",
      " Machine Learning. Related Sites. Machine Learning Resources courtesy\n",
      " of David Aha A Machine Learning Tutorial a good overview of the ... \n",
      "\n",
      "\n",
      "RANK = 3 WITH SIMILARITY = 0.8663006683370706 | DOC ID = 28\n",
      "Machine Learning\n",
      " 6.858/18.428: Machine Learning. Available Lecture Notes. ... Defining models for\n",
      " machine learning. Learning conjunctions in the mistake-bounded model. ... \n",
      "\n",
      "\n",
      "RANK = 4 WITH SIMILARITY = 0.863253443349555 | DOC ID = 77\n",
      "Machine Learning\n",
      " Machine Learning. Machine Learning Home Page (Editor) Machine Learning Home\n",
      " Page (Publisher) Machine Learning Online by Kluwer Academic Publishers: ... \n",
      "\n",
      "\n",
      "RANK = 5 WITH SIMILARITY = 0.8402114903877352 | DOC ID = 29\n",
      "Machine Learning\n",
      " 6.858/18.428: Machine Learning. ... This course deals with the following topics:\n",
      " Formal models of machine learning; Learning concepts from examples; ... \n",
      "\n",
      "\n",
      "RANK = 6 WITH SIMILARITY = 0.797989694954441 | DOC ID = 60\n",
      "Machine Learning in Bioinformatics\n",
      " ... Special Session: Machine Learning in Bioinformatics Call for papers. ... Topics of interest\n",
      " include (but are not limited to) applications of machine learning to: ... \n",
      "\n",
      "\n",
      "RANK = 7 WITH SIMILARITY = 0.7718427169854658 | DOC ID = 61\n",
      "CS 661 - Machine Learning (Salzberg)\n",
      " CS 661 - Machine Learning (Spring 1996). Steven Salzberg will ... (228K, PostScript).\n",
      " On-Line Resources in Machine Learning. Pointers to Machine ... \n",
      "\n",
      "\n",
      "RANK = 8 WITH SIMILARITY = 0.7681094906177889 | DOC ID = 17\n",
      "Machine Learning Courses\n",
      " Index of Machine Learning Courses. Machine Learning,Altay Guvenir, Bilkent University,\n",
      " Turkey. Machine Learning, Tony Martinez, Brigham Young University. ... \n",
      "\n",
      "\n",
      "RANK = 9 WITH SIMILARITY = 0.7600524008889302 | DOC ID = 20\n",
      "Machine Learning\n",
      " Machine Learning, THE ... Machine learning refers to a system capable of\n",
      " the autonomous acquisition and integration of knowledge. This ... \n",
      "\n",
      "\n",
      "RANK = 10 WITH SIMILARITY = 0.7504292624455374 | DOC ID = 67\n",
      "DTAI - Machine Learning\n",
      " ML | DTAI | Dept. of Computer Science | Faculty of Engineering | KU.Leuven,\n",
      " DTAI Machine Learning Group. [NEDERLANDS] ENGLISH Machine ... \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def getTopResults_Rocchio(query, \n",
    "                          documents, \n",
    "                          dictionary, \n",
    "                          similarity, \n",
    "                          rel_docs = [29, 36],\n",
    "                          nrel_docs = [63, 77],\n",
    "                          alpha = 0.5,\n",
    "                          beta = 0.3,\n",
    "                          gamma = 0.2,\n",
    "                          top = 10):\n",
    "    qd = Document(-1, query, dictionary)\n",
    "    qd.computeRepresentations()\n",
    "    for key, one_tf_idf in qd.tf_idf.items():\n",
    "        f1 = alpha*one_tf_idf\n",
    "        f2 = beta*(1/len(rel_docs)*sum([documents[rel_id].tf_idf[key] for rel_id in rel_docs]))\n",
    "        f3 = gamma*(1/len(nrel_docs)*sum([documents[nrel_id].tf_idf[key] for nrel_id in nrel_docs]))\n",
    "        qd.tf_idf[key] = f1 + f2 - f3\n",
    "        \n",
    "    ranks = [[d, getSimilarity(d.tf_idf, qd.tf_idf)] for d in documents]\n",
    "    ranks.sort(key=lambda x: -x[1])\n",
    "    for i in range(top):\n",
    "        print(\"RANK = \" + str(i+1) + \" WITH SIMILARITY = \" + str(ranks[i][1]) + \" | DOC ID = \" + str(ranks[i][0].doc_id))\n",
    "        print(ranks[i][0].raw_document)\n",
    "        print(\"\")\n",
    "\n",
    "getTopResults_Rocchio(\"machine learning\", documents, dictionary, getSimilarity, top = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3) WordNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3.1) Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.nltk.org/install.html\n",
    "\n",
    "import nltk \n",
    "\n",
    "nltk.download()\n",
    "\n",
    "https://www.nltk.org/data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download()\n",
    "\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition: synset = (from wiki) (information science) A set of one or more synonyms that are interchangeable in some context without changing the truth value of the proposition in which they are embedded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3.2) Display sysents for \"machine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('machine.n.01'),\n",
       " Synset('machine.n.02'),\n",
       " Synset('machine.n.03'),\n",
       " Synset('machine.n.04'),\n",
       " Synset('machine.n.05'),\n",
       " Synset('car.n.01'),\n",
       " Synset('machine.v.01'),\n",
       " Synset('machine.v.02')]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('machine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3.3) Display all definitions (.definition()) for synsets (machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('machine.n.01') any mechanical or electrical device that transmits or modifies energy to perform or assist in the performance of human tasks\n",
      "Synset('machine.n.02') an efficient person\n",
      "Synset('machine.n.03') an intricate organization that accomplishes its goals efficiently\n",
      "Synset('machine.n.04') a device for overcoming resistance at one point by applying force at some other point\n",
      "Synset('machine.n.05') a group that controls the activities of a political party\n",
      "Synset('car.n.01') a motor vehicle with four wheels; usually propelled by an internal combustion engine\n",
      "Synset('machine.v.01') turn, shape, mold, or otherwise finish by machinery\n",
      "Synset('machine.v.02') make by machinery\n"
     ]
    }
   ],
   "source": [
    "for i in wn.synsets('machine'):\n",
    "    print(i, i.definition())\n",
    "#DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3.4) For each synset (machine), display its hypernym (a word with a broad meaning constituting a category into which words with more specific meanings fall; a superordinate. For example, colour is a hypernym of red)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('machine.n.01') [Synset('device.n.01')]\n",
      "Synset('machine.n.02') [Synset('person.n.01')]\n",
      "Synset('machine.n.03') [Synset('organization.n.01')]\n",
      "Synset('machine.n.04') [Synset('mechanical_device.n.01')]\n",
      "Synset('machine.n.05') [Synset('organization.n.01')]\n",
      "Synset('car.n.01') [Synset('motor_vehicle.n.01')]\n",
      "Synset('machine.v.01') [Synset('shape.v.02')]\n",
      "Synset('machine.v.02') [Synset('produce.v.02')]\n"
     ]
    }
   ],
   "source": [
    "for i in wn.synsets('machine'):\n",
    "    print(i, i.hypernyms())\n",
    "#DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "See: http://www.nltk.org/howto/wordnet.html\n",
    "for more examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
